# Image Captioning: Applied-deep-learning-project

<p align="center">
    <center>
    <img src= "https://i.imgur.com/9g8E7Ca.jpg"
    width = 40%;
    height = auto; />
    </center>
</p>

## **Team 20**
- *Fares FEKI* (M2 Data Science_École Polytechnique)
- *Mohamed ISSA* (M2 Data Science_École Polytechnique)
- *Juhyun KIM* (M2 Data Science_École Polytechnique)
- *Rihem Mansri* (M2 Data Science_École Polytechnique)

## Project description
Get started with the dedicated notebook: [Applied-deep-learning-project/Image_captioning_with_attention_final_version.ipynb]

### Dataset description
The dataset that we used for this project is from the https://vizwiz.org/ website.

The VizWiz-Captions dataset includes:
> - 23,431 training images
> - 117,155 training captions
> -  7,750 validation images
> - 38,750 validation captions
> - 8,000 test images
> - 40,000 test captions

### Evaluation metric
The evaluation metric that we used for this project is the BLEU score.
